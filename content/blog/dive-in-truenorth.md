---
title: "Hardware Dive-In | TrueNorth"
description: "Analysis of the TrueNorth chip and article."
image: /images/blog/dive-in-truenorth/brain-to-chip.png
draft: true
date: 2023-03-12
type: "post"
tags: ["research", "hardware", "digital", "neuromorphic"]
showTableOfContents: true
---

![The beautiful TrueNorth article image](/images/blog/dive-in-truenorth/brain-to-chip.png) 

## Introduction

The TrueNorth design has been driven by seven principles:
* the architecture is a **purely event-driven one**, being Globally Asyncrhonous Locally Synchronous (GALS), with the being **completely asynchronous** inteconnection fabric among the cores, with **synchronous** cores. 
* the CMOS process employed is a **low-power** one, with the goal of minimising **static power**.
* since the brain is a **massively parallel** architecture, employing 100 billion neurons each of which has a fanout of approximately 10 thousand synapses, parallelism is a key feature of TrueNorth: a chip employes **1 million neurons** and **256 million synapses**.
* the authors claim **real-time** operation, which translates to a global time synchronisations of **1ms**, i.e. the neurons are updated and spike every millisecond.
* the architecture is **scalable**: multiple cores can be put together, and the local synchronicity of the cores prevents the problems related to **global clock signal skew** in modern digital circuits.
* **redundancy** is employed in the design, especially in the **memory circuits**, to make the chip **tolerant to defects**.
* the chip operation corresponds perfectly to the software operation, when using the IBM TrueNorth application design software.

Designing an asynchronous circuit is a very difficult task, since no VLSI EDAs are available for this kind of design; hence, the TrueNorth designers have decided to use conventional EDAs for the synchronous cores design and **custom design tools and flows** for the asynchronous interconnection fabric. 

## Architecture 

The TrueNorth chip is not a Von Neumann machine! But what does this mean?

{{< 
    figure 
    src="/images/blog/dive-in-truenorth/von-neumann-architecture.png" 
    caption="The Von Neumann architecture."
    attr="Source"
    attrlink="https://en.wikipedia.org/wiki/Von_Neumann_architecture"
>}}
In a Von Neumann machine, like the one depicted above (source: )the processing unit is **separated** from the memory one, which stores both data and instructions. The processor reads the instructions from the memory, decodes them, retrieves the data on which it needs to operate from the same memory and, then, executes the instructions.

In a neuromorphic chip, instead, memory and computational units are **co-located**. The neuron constitutes the computational unit (to be precise, it is the **soma**), while the synapses and the membrane are the data on which the neuron operates. The chip is programmed by deciding **which neurons are connected to which**; hence, we do not write instructions to be executed to a memory, but we program the neurons interconnections! 

{{<
    figure
    src="/images/blog/dive-in-truenorth/crossbar.png"
    caption="A fully-connected neural network (left) and its logical representation in the TrueNorth chip (right)."
    attr="Source"
    attrlink="https://redwood.berkeley.edu/wp-content/uploads/2021/08/Akopyan2015.pdf"
>}}

In the figure above, the logical representation of a TrueNorth core is reported. Consider the sub-figure on the left: an input neuron (also denoted as **pre-synaptic**) is denoted with the white AND-gate shape, while an output neuron (also denoted as **post-synaptic**) is depicted by a gray triangle shape. The output terminal of a neuron is called **axon**, while the input one **dendrite**; two neurons are connected if their axon and dendrite are, and the connection is called **synapse**. Hence, a synapse corresponds to one of the black lines interconnecting input and output neurons in the subfigure on the left. 

How to this on a chip? Look at the subfigure on the right. Incoming **spikes**, i.e. the ones generated by the neurons in the network, are stored in input **buffers**: this is because TrueNorth evaluates data only when a tick is passed, i.e. every 1ms; this means that until a tick is passed, all the incoming spikes are stored in buffers, that are then read at the tick clock. 

If a neuron is interconnected to another, a black dot is placed to interconnect the pre-synaptic axon to the post-synaptic dendrite, in the subfigure on the right. Let's get to the equations now! 

The neuron model employed in TrueNorth is the **Leaky Integrate and Fire** (LIF) one. The update equation is the following:

$$ V_{j}[t] = V_{j}[t-1] + \sum_{i=0}^{255} A_{i}[t] \cdot w_{i,j} \cdot s_{j}^{G_{i}} - \lambda_{j}$$

Lots of variables! Let's study this mess:
* $V_{j}[t]$ represents the **membrane potential** of the $j$-th post-synaptic neuron at timestamp $t$.
* in a TrueNorth core, each post-synaptic neuron can be connected to **256** pre-synaptic neurons; this is why the sum spans from $i=0$ to $i=255$.
* $A_{i}[t]$ corresponds to the $i$-th pre-synaptic neuron spike: its equal to 1 if that neurons has spiked at timestamp $t$ and 0 otherwise.
* $w_{i,j}$ is a binary variable that the determines if the $i$-th pre-synaptic neuron is connected to the $j$-th post-synaptic neuron: when they are, $w_{i,j}=1$, otherwise $w_{i,j}=0$.
* $s_{j}^{G_{i}}$ determines the strength of the connection, i.e. the **synapse weight** value. In TrueNorth, there are **four** types of axons, and the axon of the $i$-th pre-synaptic neuron is identified by a value of the variable $G_{i} \in \\{1,2,3,4\\}$; the dendrite of the $j$-th post-synaptic neuron is identified by $s_{j}$.
* $\lambda_{j}$ is the **leakage** value. At each timestamp $t$, this fixed quantity is subtracted from the membrane potential. 

In the equation, the spike mechanism is missing! The authors denote the spiking threshold of the $j$-th neuron with $\alpha_{j}$: when $V_{j}[t] \gt \alpha_{j}$, the neuron potential is reset to the **rest** one, denoted with $R_{j}$. The following is the pseudo-code, employing the C ternary operator (LaTeX in Markdown is a mess):

$$V_{j}^{\*}[t] \triangleq V_{j}[t-1] + \sum_{i=0}^{255} A_{i}[t] \cdot w_{i,j} \cdot s_{j}^{G_{i}} - \lambda_{j}$$

$$
% \begin{equation}
    V_{j}[t] = V_{j}^{\*}[t] \gt \alpha_{j} ~ ? ~ R_{j} ~ : ~ V_{j}^{\*}[t]
        % \begin{cases} 
        % V_{j}^{\*}[t] & \text{if $V_{j}^{\*}[t] \le \alpha_{j}$}\\
        % R_{j} & \text{if $V_{j}^{\*}[t] \gt \alpha_{j}$}
        % \end{cases}
% \end{equation}
$$

One may be wondering what the PRNG block stands for in the figure: it is a **pseudo random number generator**, and it is used to provide stochastic spike integrataion, leakage and threshold for the post-synaptic neurons.

What we have discussed until now is the model of a TrueNorth core: in this, 256 neurons are placed, each of which can be connected to other 256 neurons, which can be in the same core but also **out of it**. This is accomplished by interconnecting the neurons and multiple cores using a **2D mesh** network; here comes the fun stuff, because the out-of-chip communication is completely **asynchronous**. Are you ready for an headache?

## Bibliography

